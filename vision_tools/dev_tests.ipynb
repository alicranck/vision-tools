{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time\n",
    "import yaml\n",
    "from PIL.Image import Image as PILImage\n",
    "import cv2\n",
    "\n",
    "# sys.path.append(\"/home/alicranck/almog/projects/vision-tools/vision_tools\")\n",
    "\n",
    "from vision_tools.core.tools.detection import OpenVocabularyDetector\n",
    "from vision_tools.core.tools.captioning import Captioner\n",
    "from vision_tools.core.tools.embedder import CLIPEmbedder\n",
    "from vision_tools.core.tools.base_tool import BaseVisionTool\n",
    "from vision_tools.engine.video_engine import VideoInferenceEngine\n",
    "from vision_tools.core.tools.pipeline import VisionPipeline, PipelineConfig\n",
    "from vision_tools.utils.image_utils import base64_encode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0a5260",
   "metadata": {},
   "source": [
    "## Test tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870f666",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513923f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_video_url = \"https://cdn.pixabay.com/video/2020/11/13/56310-479197605_large.mp4\"\n",
    "\n",
    "\n",
    "def time_run(tool: BaseVisionTool, n_frames: int):\n",
    "    \n",
    "    \n",
    "    cap = cv2.VideoCapture(demo_video_url)\n",
    "\n",
    "    processed_frames = 0\n",
    "    times = []\n",
    "    while cap.isOpened() and processed_frames < n_frames:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "        response = tool.process(frame, {})\n",
    "        end_time = time.time()\n",
    "        \n",
    "        processed_frames += 1\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    print(f\"Average time: {sum(times[2:]) / len(times[2:])}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cad138",
   "metadata": {},
   "source": [
    "### Detector / Segmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"/home/alicranck/almog/projects/vision-tools/vision_tools/core/configs/ov_detection.yaml\"\n",
    "with open(cfg_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "cfg[\"vocabulary\"] = [\"person\", \"car\", \"bus\"]\n",
    "\n",
    "detector = OpenVocabularyDetector(cfg['model'], cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.model.names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c7ac05",
   "metadata": {},
   "source": [
    "### Captioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "captioner = LlamaCppCaptioner(\"ggml-org/SmolVLM2-256M-Video-Instruct-GGUF:Q8_0\", {\"imgsz\": 480})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11907b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_run(captioner, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606732ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolate_box(boxes: list) -> list:\n",
    "    xyxy_boxes = np.array([box.xyxy.cpu().tolist() for box in boxes])\n",
    "    diffs = np.diff(xyxy_boxes, axis=0)\n",
    "    mean_diff = np.ma.average(diffs, axis=0, \n",
    "                        weights=range(len(diffs)))\n",
    "    next_xyxy_box = xyxy_boxes[-1] + mean_diff\n",
    "    return next_xyxy_box.tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904356a1",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39296732",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"/home/alicranck/almog/projects/vision-tools/vision_tools/core/configs/embedding.yaml\"\n",
    "with open(cfg_path, 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "embedder = CLIPEmbedder(cfg[\"model\"], cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf123d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/alicranck/Downloads/download.jpeg\"\n",
    "res = embedder.process(image_path, {})\n",
    "emb = res[0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "\n",
    "clip_model = embedder.model\n",
    "text = \"shoe\"\n",
    "\n",
    "text_tokens = clip.tokenize([text]).to(embedder.device)\n",
    "text_features = embedder.model.encode_text(text_tokens)\n",
    "text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "text_embedding = text_features.cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24945b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "cosine_similarity(text_embedding.squeeze().reshape(1, -1), np.array(emb).squeeze().reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b71d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(emb).squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf29de0",
   "metadata": {},
   "source": [
    "## Video engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117858c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = PipelineConfig(\n",
    "    tool_settings={\n",
    "        \"embedding\": {\n",
    "            \"trigger\": {\"type\": \"stride\", \"value\": 150}\n",
    "        },\n",
    "        \"ov_detection\": {\n",
    "            \"vocabulary\": [\"person\", \"car\", \"dog\", \"cat\", \"chair\"],\n",
    "            \"trigger\": {\"type\": \"stride\", \"value\": 150}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "pipeline = VisionPipeline(pipeline_config)\n",
    "engine = VideoInferenceEngine(pipeline, \"/home/alicranck/Downloads/הכנסה.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16af9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _persist_data(data):\n",
    "    tools_run = data['tools_run']\n",
    "    if not tools_run:\n",
    "        return\n",
    "    \n",
    "    timestamp = data['metadata']['timestamp']\n",
    "    metadata = {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"data\": data[\"embedding\"]\n",
    "    }\n",
    "\n",
    "    print(metadata)\n",
    "    \n",
    "\n",
    "\n",
    "# Run engine\n",
    "async for _ in engine.run_inference(\n",
    "    on_data=_persist_data, \n",
    "    buffer_delay=0, \n",
    "    realtime=False\n",
    "):\n",
    "    pass\n",
    "\n",
    "# Cleanup\n",
    "pipeline.unload_tools()\n",
    "logger.info(f\"Finished indexing {video_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
